
# Clasificaci贸n de Siniestros
Repositorio para el proyecto de clasificaci贸n de siniestros dentro de la asignatura Proyecto Desarrollo de soluciones de la Universidad de Los Andes, sigue las pr谩cticas de MLOps para la gesti贸n de datos, entrenamiento de modelos y despliegue en producci贸n. La estructura est谩 dise帽ada para garantizar trazabilidad, modularidad y escalabilidad en proyectos de Machine Learning.


##  Equipo de Trabajo


A continuaci贸n, se listan los miembros del equipo junto con sus usuarios de GitHub:

| Nombre   | Usuario de GitHub  |
|----------|-------------------|
| Alyona Ivanova | [@AlyonaCIA](https://github.com/AlyonaCIA) |
| Andr茅s Forero  | [@AndresF100](https://github.com/AndresF100) |
| Camilo Matson | [@camilomath](https://github.com/camilomath) |
| Santiago Calder贸n | [@SantiagoCalderonLopezUniandes](https://github.com/SantiagoCalderonLopezUniandes)|


##  Estructura del Repositorio
```
 Repo desarrollo soluciones
     api
     config
     dashboard
     data
     dist
     docker
     Docs
     notebooks
     src
```

### Descripci贸n de Carpetas
* **api/**: Contiene el c贸digo de la API en FastAPI para exponer el modelo, incluyendo app.py y adaptadores.
* **config/**: Almacena archivos de configuraci贸n, credenciales (como dvc-key.json), y comandos para acceder a recursos externos (como instancias de EC2).
* **dashboard/**: C贸digo del tablero interactivo para visualizar m茅tricas y predicciones, organizado en `components/` y `utils/`.  
* **data/**: Contiene los datos del proyecto en diferentes fases (se obtiene por dvc):  
    - **raw/**: Datos originales sin procesar.  
    - **processed/**: Datos transformados para entrenar y validar el modelo.  
    - **visual/**: Datos espec铆ficos para visualizaci贸n en el dashboard.
* **dist/**: Modelo empaquetado listo para instalaci贸n.
* **docker/**: Incluye Dockerfiles para construir im谩genes de la API y el dashboard, facilitando el despliegue en contenedores.  
* **Docs/**: Documentaci贸n del proyecto, incluyendo an谩lisis exploratorio y descripci贸n del problema.  
* **notebooks/**: Notebooks de Jupyter para la exploraci贸n de datos, preprocesamiento y experimentos.  
* **src/**: C贸digo fuente principal, dividido en subm贸dulos:  
    - **data_preprocessing/**: Scripts para limpieza, transformaci贸n y creaci贸n del pipeline de preprocesamiento.  
    - **models/**: Implementaci贸n de distintos modelos (XGBoost, RandomForest, etc.), evaluaciones y b煤squeda de hiperpar谩metros.  
    - **modelo_triage/**: Utilidades para cargar el modelo y transformar entradas antes de realizar predicciones.
 
  
##  Requisitos

Para descargar los datos, pide a uno de los creadores del repositorio que te comparta el **dvc-key.json**, agregalo a tu carpeta config, y ejecuta en dvc:
    
```bash
dvc remote modify gcsremote credentialpath ruta/a/dvc-key.json
```
